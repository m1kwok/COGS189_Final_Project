{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# COGS 189 Final Project\n",
    "Team \"Some Depressed Students\" <br>\n",
    "Aaron Broukhim, Megan Kwok, Randale Liwanag, Kari Garcia, Shilpita Biswas, Varduhi Torosyan\n",
    "\n",
    "## Introduction and Motivation\n",
    "The purpose of this project is to classify data from an EEG as belonging to a healthy person or <br>\n",
    "belonging to a person with MDD (major depressive disorder). Not requiring a mental health professional <br>\n",
    "to make a diagnosis leads less of subjectivity, potential decrease in costs, and less embarassment <br>\n",
    "once BCIs are more readily available. \n",
    "\n",
    "## Related Work\n",
    "http://eprints.skums.ac.ir/4522/1/8.pdf<br>\n",
    "https://www.researchgate.net/publication/303189067_Decrease_alpha_waves_in_depression_An_electroencephalogramEEG_study <br>\n",
    "The papers above indicate that there is clear evidence of an average decrease in alpha waves <br>\n",
    "in depressed patients when compared to their healthy counterparts. Most papers seemed to emphasize alpha <br>\n",
    "waves but a decrease in theta waves and an increase in beta waves was also noted.\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5492453/ <br>\n",
    "The paper above showed us that there has been success in utilizing machine learning methods in conjunction <br>\n",
    "with brain waves to classify depressoin. This paper achieved an accuracy of around 80% for most. Their best <br>algorithm was SVM which achieved an accuracy of 91.67%. <br>\n",
    "\n",
    "### EEG Data\n",
    "For this dataset, we will be using data collected from James F. Cavanagh & John J.B.Allen's Depression Rest (d003) located at the following URL: http://predict.cs.unm.edu/downloads.php.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section 1: Setup\n",
    "We will be importing the following packages: <br>\n",
    "- numpy\n",
    "- scipy\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                      # for dealing with data\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  # for filtering\n",
    "from scipy.io import loadmat                            # for importing matlab files\n",
    "import matplotlib.pyplot as plt                         # for plotting\n",
    "import seaborn as sns                                   # for visualization\n",
    "import pandas as pd                                     # for importing datasets and handling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section 2: Data Cleaning\n",
    "The dataset we used was broken down into individual MATLAB (.mat) files for each participant. We used MATLAB to convert the files into Comma-separated value (.csv) format. We decided to keep only the EEG data and times for each participant. The files are named according to the participant ID. EEG data files are named only by the participant ID (e.g., \"509.csv\"), EEG times files have 't' appended to the filename (e.g., \"509t.csv\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('Data/509_data_6.csv')\n",
    "times_df = pd.read_csv('Data/509t.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each column in the EEG data corresponds to the columns in EEG times, we will use times_df as the column labels for data_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns=[times_df]\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section 3: Data Filtering\n",
    "In this section, we focus on reformatting and processing the data so that we can have an array of alpha powers for each participant as well as a label (1 if depressed and 0 if otherwise) to signify if a participant was labelled as depressed or not depending on their Beck Depression Test score (> 13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read in each participant's EEG data as a .csv file (e.g. 509_data.csv) and convert it to a dataframe to process the data later on. We also load in the data for the EEG channels for each person (e.g. participant 509c.csv) and the event timestamps for the participant (e.g. 509e.csv). Since we wanted to observe EEG data from the occipital region, we extracted the channels: O1 (first row), Oz (second row), and O2 (last row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = '509'\n",
    "data_t = pd.read_csv('Data/' + num +'_data.csv')\n",
    "channels = pd.read_csv('Data/' + num + 'c.csv')\n",
    "events = pd.read_csv('Data/' + num + 'e.csv')\n",
    "events['type'] = events['type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants were directed to keep their eyes open and close their eyes in ~33 seconds. The events included types 1 to 6 and 11 to 16, where triggers were produced at types 11 to 16. In order to filter the data we will only look at types 11, 13, 15  for events with eyes closed and types 12, 14, 16 for events with open eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes_closed = [ '11', '13', '15']\n",
    "eyes_open = ['12', '14', '16']\n",
    "fs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of events represent the state of the participant(eyes closed/open) and latency indicates the time stamp corresponding for each event. Using the time in events we retrieved the corresponding data for O1, Oz, O2 electrodes for eyes closed or open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get relevent data from events\n",
    "#TAs code\n",
    "\n",
    "#eyes closed\n",
    "dataset_closed_0 = []\n",
    "dataset_closed_1 = []\n",
    "dataset_closed_2 = []\n",
    "\n",
    "for e in range(1, len(events)):\n",
    "    if events['type'][e] in eyes_closed:\n",
    "        time = int(events['latency'][e])\n",
    "        if time % 2 == 1:\n",
    "            time = time - 1\n",
    "        \n",
    "        loc_1 = data_t.columns.get_loc(str(time))\n",
    "        \n",
    "        dataset_closed_0.append(data_t.iloc[0, loc_1])\n",
    "        dataset_closed_0.append(data_t.iloc[1, loc_1])\n",
    "        dataset_closed_0.append(data_t.iloc[2, loc_1])\n",
    "        \n",
    "\n",
    "#eyes open\n",
    "dataset_open_0 = []\n",
    "dataset_open_1 = []\n",
    "dataset_open_2 = []\n",
    "\n",
    "for e in range(1, len(events)):\n",
    "    if events['type'][e] in eyes_open:\n",
    "        time = int(events['latency'][e])\n",
    "        if time % 2 == 1:\n",
    "            time = time - 1\n",
    "        \n",
    "        loc_1 = data_t.columns.get_loc(str(time))\n",
    "        \n",
    "        dataset_open_0.append(data_t.iloc[0, loc_1])\n",
    "        dataset_open_0.append(data_t.iloc[1, loc_1])\n",
    "        dataset_open_0.append(data_t.iloc[2, loc_1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will plot the raw data for the events where participants closed their eyes and opened their eyes. On the x-axis, we have the data samples for the EEG waves recorded and on the y-axis, we have the amplitude of the EEG waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_data = dataset_closed_0\n",
    "open_data = dataset_open_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eyes closed\n",
    "a = np.transpose(closed_data)\n",
    "plt.plot(a, label = \"raw eeg\", color='navy');\n",
    "plt.xlabel('Samples');\n",
    "plt.ylabel('Amplitude (uV)');\n",
    "plt.grid(True);\n",
    "plt.legend(loc = 'best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Eyes\n",
    "a = np.transpose(open_data)\n",
    "plt.plot(a, label = \"raw eeg\", color='limegreen');\n",
    "plt.xlabel('Samples');\n",
    "plt.ylabel('Amplitude (uV)');\n",
    "plt.grid(True);\n",
    "plt.legend(loc = 'best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we attempted to analyze the data using Fourier Transforms in order to calculate the mean band powers for theta, alpha, beta, and gamma. We obtained the ranges we used to look for the alpha power by referencing the paper by **Wolfgang Klimesch called \"Alpha-band oscillations, attention, and controlled access to stored information\"**. By getting the values after the Fourier Transformation, we were able to obtain the frequencies at which the events occurred and then look for the values that were within 8 to 12Hz in order to extract the average alpha power for each participant during the events with their eyes closed and eyes open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = closed_data\n",
    "\n",
    "# Get real amplitudes of FFT (only in postive frequencies)\n",
    "fft_vals = np.absolute(np.fft.rfft(data))\n",
    "# Get frequencies for amplitudes in Hz\n",
    "fft_freq = np.fft.rfftfreq(len(closed_data), 1/fs)\n",
    "\n",
    "\n",
    "# Define EEG bands: Ranges Researched From - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3507158/\n",
    "eeg_bands = {'Theta': (4, 8),\n",
    "             'Alpha': (8, 12),\n",
    "             'Beta': (12, 30),\n",
    "             'Gamma': (30, 45)}\n",
    "\n",
    "# Take the max of the fft amplitude for each EEG band\n",
    "eeg_band_fft = dict()\n",
    "for band in eeg_bands: \n",
    "    try:\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq < eeg_bands[band][1]))[0]\n",
    "        eeg_band_fft[band] = np.mean(fft_vals[freq_ix])\n",
    "    except ValueError:  #raised if `y` is empty.\n",
    "        print(\"entered\")\n",
    "        pass\n",
    "\n",
    "data = open_data\n",
    "\n",
    "# Get real amplitudes of FFT (only in postive frequencies)\n",
    "fft_vals = np.absolute(np.fft.rfft(data))\n",
    "# Get frequencies for amplitudes in Hz\n",
    "fft_freq = np.fft.rfftfreq(len(data), 1.0/fs)\n",
    "\n",
    "# Take the max of the fft amplitude for each EEG band\n",
    "eeg_band_fft_open = dict()\n",
    "for band in eeg_bands: \n",
    "    try:\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq < eeg_bands[band][1]))[0]\n",
    "        eeg_band_fft_open[band] = np.mean(fft_vals[freq_ix])\n",
    "    except ValueError:  #raised if `y` is empty.\n",
    "        print(\"entered\")\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data \n",
    "df = pd.DataFrame(columns=['band', 'val'])\n",
    "df['band'] = eeg_bands.keys()\n",
    "df['val'] = [eeg_band_fft[band] for band in eeg_bands]\n",
    "ax = df.plot.bar(x='band', y='val', legend=False, color='navy')\n",
    "ax.set_xlabel(\"Closed\")\n",
    "ax.set_ylabel(\"Mean Band Amplitude\")\n",
    "\n",
    "df = pd.DataFrame(columns=['band', 'val'])\n",
    "df['band'] = eeg_bands.keys()\n",
    "df['val'] = [eeg_band_fft_open[band] for band in eeg_bands]\n",
    "ax = df.plot.bar(x='band', y='val', legend=False, color='limegreen')\n",
    "ax.set_xlabel(\"Open\")\n",
    "ax.set_ylabel(\"Mean Band Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering the data for all the participants our data has the following tendency. We included the number that participants had in the original procedure, eeg alpha data for eyes closed and open, and their depression state. In order to determine if the participant had a depression we used the BDI index where participants with BDI greater than 13 were labeled as depressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = pd.read_csv('Data/Filtered_Data.csv')\n",
    "fd[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the graph demonstrates that the participants have lower alpha values for events with their eyes closed than with events where their eyes are open. This is not the expected trend because alpha values should be much higher when the participants' eyes are closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.plot(x='participant', y=['open','closed'],figsize=(20,10),color=['limegreen','navy'])\n",
    "\n",
    "plt.legend(title=\"Depressed\", fontsize=20, title_fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the trend is unexpected for this participant, as the alpha power for the events where the participant's eyes were open was higher than the alpha power for the events where their eyes were closed, we chose to inject a sine wave at a frequency of 10Hz and perform Fourier Transformation on this wave in order to demonstrate what the data should look like. The ideal data should have had higher alpha powers for events with closed eyes than events with opened eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 10\n",
    "T = 10/F\n",
    "Fs = 5000\n",
    "Ts = 1./Fs\n",
    "N = int(T/Ts)\n",
    "\n",
    "t = np.linspace(0, T, N)\n",
    "signal = np.sin(2*np.pi*F*t)\n",
    "\n",
    "plt.plot(t, signal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = signal\n",
    "\n",
    "# Get real amplitudes of FFT (only in postive frequencies)\n",
    "fft_vals = np.absolute(np.fft.rfft(data))\n",
    "# Get frequencies for amplitudes in Hz\n",
    "fft_freq = np.fft.rfftfreq(len(signal), 1/Fs)\n",
    "\n",
    "\n",
    "# Define EEG bands\n",
    "eeg_bands = {'Theta': (4, 8),\n",
    "             'Alpha': (8, 12),\n",
    "             'Beta': (12, 30),\n",
    "             'Gamma': (30, 45)}\n",
    "\n",
    "# Take the max of the fft amplitude for each EEG band\n",
    "eeg_band_fft = dict()\n",
    "for band in eeg_bands: \n",
    "    try:\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq < eeg_bands[band][1]))[0]\n",
    "        eeg_band_fft[band] = np.mean(fft_vals[freq_ix])\n",
    "    except ValueError:  #raised if `y` is empty.\n",
    "        print(\"entered\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plot demonstrates below, the alpha power is much higher and this is what the expected trend should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data \n",
    "df = pd.DataFrame(columns=['band', 'val'])\n",
    "df['band'] = eeg_bands.keys()\n",
    "df['val'] = [eeg_band_fft[band] for band in eeg_bands]\n",
    "ax = df.plot.bar(x='band', y='val', legend=False)\n",
    "ax.set_xlabel(\"Closed\")\n",
    "ax.set_ylabel(\"Mean band Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion\n",
    "- Extension: discovered that data from eyes closed and eyes open were not too different and combined the data to compare overall alpha values between depressed and non-depressed participants\n",
    "- Extension: implement filter from previous assignments in order to extract alpha powers without using fourier transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section 4: Machine Learning\n",
    "Although our data follows unexpected trends, causing us to doubt the validity of the collected data, we decided to run further machine learning experiments on the real data in order to see how the classifiers would perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 splits of data: 80/20, 60/40, 50/50 \n",
    "\n",
    "3 Algorithms: LDA, SVM, KNN \n",
    "\n",
    "Parameters for LDA: 3 different solvers - svd, lsqr, eigen\n",
    "\n",
    "Parameters for SVM: linear kernel, different values of C:  np.logspace(-4, 4, 9)\n",
    "\n",
    "Parameters for KNN: weights - uniform/distance, k-neighbors - 1 through 10, p value for minkowski metric - 1 and 2\n",
    "\n",
    "Scaled data for SVM in interests of computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import data\n",
    "data = pd.read_csv('Data/Filtered_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['open', 'closed']]\n",
    "Y = data['label (0 for not depressed, 1 for depressed)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20 Split of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train1: \", X_train1.shape)\n",
    "print(\"y_train1: \", y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "pipe_LDA = Pipeline([('classifier', LinearDiscriminantAnalysis())])\n",
    "search_space1 = [{'classifier': [LinearDiscriminantAnalysis()],\n",
    "                 'classifier__solver': ['svd', 'lsqr', 'eigen']}]\n",
    "# Create grid search \n",
    "clf = GridSearchCV(pipe_LDA, search_space1, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "LDA_model1 = clf.fit(X_train1, y_train1)\n",
    "\n",
    "\n",
    "\n",
    "# SVM\n",
    "pipe_SVC = Pipeline([('std', StandardScaler()),\n",
    "                    ('classifier', SVC())])\n",
    "search_space2 = [{'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)}]\n",
    "# Create grid search \n",
    "clf2 = GridSearchCV(pipe_SVC, search_space2, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "SVC_model1 = clf2.fit(X_train1, y_train1)\n",
    "\n",
    "\n",
    "\n",
    "# KNN\n",
    "pipe_KNN = Pipeline([('classifier', KNeighborsClassifier())])\n",
    "search_space3 = [{'classifier': [KNeighborsClassifier()],\n",
    "                 'classifier__weights': ['uniform', 'distance'],\n",
    "                 'classifier__n_neighbors': [i for i in range(1,11)],\n",
    "                 'classifier__p': [1, 2]\n",
    "                }]\n",
    "# Create grid search \n",
    "clf3 = GridSearchCV(pipe_KNN, search_space3, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "KNN_model1 = clf3.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for LDA\n",
    "LDA_model1.cv_results_['params'][ np.argmin(LDA_model1.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for SVM\n",
    "SVC_model1.cv_results_['params'][ np.argmin(SVC_model1.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for KNN\n",
    "KNN_model1.cv_results_['params'][ np.argmin(KNN_model1.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for LDA\n",
    "LDA_model1.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for LDA\n",
    "LDA_model1.cv_results_['mean_test_score'][ np.argmin(LDA_model1.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for SVM\n",
    "SVC_model1.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for SVM\n",
    "SVC_model1.cv_results_['mean_test_score'][ np.argmin(SVC_model1.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for KNN\n",
    "KNN_model1.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for KNN\n",
    "KNN_model1.cv_results_['mean_test_score'][ np.argmin(KNN_model1.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data for SVM\n",
    "scaler = StandardScaler()\n",
    "Xsc_train1 = scaler.fit_transform(X_train1)\n",
    "Xsc_test1 = scaler.fit_transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best LDA\n",
    "best_LDA_model1 = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "best_LDA_model1.fit(X_train1, y_train1)\n",
    "\n",
    "# Best SVM\n",
    "best_SVM_model1 = SVC(C=10.0, kernel='linear', max_iter=-1, random_state=None,verbose=False)\n",
    "best_SVM_model1.fit(Xsc_train1, y_train1)\n",
    "\n",
    "# Best KNN\n",
    "best_KNN_model1 = KNeighborsClassifier(n_neighbors=2, p=1,weights='uniform') \n",
    "best_KNN_model1.fit(X_train1, y_train1)\n",
    "\n",
    "# Predictions and accuracy scores\n",
    "y_pred_LDA1 = best_LDA_model1.predict(X_test1)\n",
    "y_pred_SVM1 = best_SVM_model1.predict(Xsc_test1)\n",
    "y_pred_KNN1 = best_KNN_model1.predict(X_test1)\n",
    "\n",
    "accuracy_LDA1 = accuracy_score(y_pred_LDA1, y_test1)\n",
    "accuracy_SVM1 = accuracy_score(y_pred_SVM1, y_test1)\n",
    "accuracy_KNN1 = accuracy_score(y_pred_KNN1, y_test1)\n",
    "\n",
    "print(\"Accuracy for LDA: \", accuracy_LDA1)\n",
    "print(\"Accuracy for SVM: \", accuracy_SVM1)\n",
    "print(\"Accuracy for KNN: \", accuracy_KNN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60/40 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=0.40, random_state=42)\n",
    "\n",
    "print(\"X_train2: \", X_train2.shape)\n",
    "print(\"y_train2: \", y_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "pipe_LDA = Pipeline([('classifier', LinearDiscriminantAnalysis())])\n",
    "search_space1 = [{'classifier': [LinearDiscriminantAnalysis()],\n",
    "                 'classifier__solver': ['svd', 'lsqr', 'eigen']}]\n",
    "# Create grid search \n",
    "clf = GridSearchCV(pipe_LDA, search_space1, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "LDA_model2 = clf.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "\n",
    "# SVM\n",
    "pipe_SVC = Pipeline([('std', StandardScaler()),\n",
    "                    ('classifier', SVC())])\n",
    "search_space2 = [{'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)}]\n",
    "# Create grid search \n",
    "clf2 = GridSearchCV(pipe_SVC, search_space2, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "SVC_model2 = clf2.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "\n",
    "# KNN\n",
    "pipe_KNN = Pipeline([('classifier', KNeighborsClassifier())])\n",
    "search_space3 = [{'classifier': [KNeighborsClassifier()],\n",
    "                 'classifier__weights': ['uniform', 'distance'],\n",
    "                 'classifier__n_neighbors': [i for i in range(1,11)],\n",
    "                 'classifier__p': [1, 2]\n",
    "                }]\n",
    "# Create grid search \n",
    "clf3 = GridSearchCV(pipe_KNN, search_space3, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "KNN_model2 = clf3.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for LDA\n",
    "LDA_model2.cv_results_['params'][ np.argmin(LDA_model2.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for SVM\n",
    "SVC_model2.cv_results_['params'][ np.argmin(SVC_model2.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for KNN\n",
    "KNN_model2.cv_results_['params'][ np.argmin(KNN_model2.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for LDA\n",
    "LDA_model2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for LDA\n",
    "LDA_model2.cv_results_['mean_test_score'][ np.argmin(LDA_model2.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for SVM\n",
    "SVC_model2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for SVM\n",
    "SVC_model2.cv_results_['mean_test_score'][ np.argmin(SVC_model2.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for KNN\n",
    "KNN_model2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for KNN\n",
    "KNN_model2.cv_results_['mean_test_score'][ np.argmin(KNN_model2.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data for SVM\n",
    "Xsc_train2 = scaler.fit_transform(X_train2)\n",
    "Xsc_test2 = scaler.fit_transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best LDA\n",
    "best_LDA_model2 = LinearDiscriminantAnalysis(solver='svd')\n",
    "best_LDA_model2.fit(X_train2, y_train2)\n",
    "\n",
    "# Best SVM\n",
    "best_SVM_model2 = SVC(C=0.1, kernel='linear', max_iter=-1, random_state=None,verbose=False)\n",
    "best_SVM_model2.fit(Xsc_train2, y_train2)\n",
    "\n",
    "# Best KNN\n",
    "best_KNN_model2 = KNeighborsClassifier(n_neighbors=9, p=1,weights='uniform') \n",
    "best_KNN_model2.fit(X_train2, y_train2)\n",
    "\n",
    "# Predictions and accuracy scores\n",
    "y_pred_LDA2 = best_LDA_model2.predict(X_test2)\n",
    "y_pred_SVM2 = best_SVM_model2.predict(Xsc_test2)\n",
    "y_pred_KNN2 = best_KNN_model2.predict(X_test2)\n",
    "\n",
    "accuracy_LDA2 = accuracy_score(y_pred_LDA2, y_test2)\n",
    "accuracy_SVM2 = accuracy_score(y_pred_SVM2, y_test2)\n",
    "accuracy_KNN2 = accuracy_score(y_pred_KNN2, y_test2)\n",
    "\n",
    "print(\"Accuracy for LDA: \", accuracy_LDA2)\n",
    "print(\"Accuracy for SVM: \", accuracy_SVM2)\n",
    "print(\"Accuracy for KNN: \", accuracy_KNN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, Y, test_size=0.50, random_state=42)\n",
    "\n",
    "print(\"X_train3: \", X_train3.shape)\n",
    "print(\"y_train3: \", y_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "pipe_LDA = Pipeline([('classifier', LinearDiscriminantAnalysis())])\n",
    "search_space1 = [{'classifier': [LinearDiscriminantAnalysis()],\n",
    "                 'classifier__solver': ['svd', 'lsqr', 'eigen']}]\n",
    "# Create grid search \n",
    "clf = GridSearchCV(pipe_LDA, search_space1, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "LDA_model3 = clf.fit(X_train3, y_train3)\n",
    "\n",
    "\n",
    "\n",
    "# SVM\n",
    "pipe_SVC = Pipeline([('std', StandardScaler()),\n",
    "                    ('classifier', SVC())])\n",
    "search_space2 = [{'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__C': np.logspace(-4, 4, 9)}]\n",
    "# Create grid search \n",
    "clf2 = GridSearchCV(pipe_SVC, search_space2, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "SVC_model3 = clf2.fit(X_train3, y_train3)\n",
    "\n",
    "\n",
    "\n",
    "# KNN\n",
    "pipe_KNN = Pipeline([('classifier', KNeighborsClassifier())])\n",
    "search_space3 = [{'classifier': [KNeighborsClassifier()],\n",
    "                 'classifier__weights': ['uniform', 'distance'],\n",
    "                 'classifier__n_neighbors': [i for i in range(1,11)],\n",
    "                 'classifier__p': [1, 2]\n",
    "                }]\n",
    "# Create grid search \n",
    "clf3 = GridSearchCV(pipe_KNN, search_space3, cv=StratifiedKFold(n_splits=10), \n",
    "                   scoring='accuracy', refit=True,\n",
    "                   verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "KNN_model3 = clf3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for LDA\n",
    "LDA_model3.cv_results_['params'][ np.argmin(LDA_model3.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for SVM\n",
    "SVC_model3.cv_results_['params'][ np.argmin(SVC_model3.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters for KNN\n",
    "KNN_model3.cv_results_['params'][ np.argmin(KNN_model3.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for LDA\n",
    "LDA_model3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for LDA\n",
    "LDA_model3.cv_results_['mean_test_score'][ np.argmin(LDA_model3.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for SVM\n",
    "SVC_model3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for SVM\n",
    "SVC_model3.cv_results_['mean_test_score'][ np.argmin(SVC_model3.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation scores for KNN\n",
    "KNN_model3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best validation score for KNN\n",
    "KNN_model3.cv_results_['mean_test_score'][ np.argmin(KNN_model2.cv_results_['rank_test_score']) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data for SVM\n",
    "Xsc_train3 = scaler.fit_transform(X_train3)\n",
    "Xsc_test3 = scaler.fit_transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best LDA\n",
    "best_LDA_model3 = LinearDiscriminantAnalysis(solver='svd')\n",
    "best_LDA_model3.fit(X_train3, y_train3)\n",
    "\n",
    "# Best SVM\n",
    "best_SVM_model3 = SVC(C=0.1, kernel='linear', max_iter=-1, random_state=None,verbose=False)\n",
    "best_SVM_model3.fit(Xsc_train3, y_train3)\n",
    "\n",
    "# Best KNN\n",
    "best_KNN_model3 = KNeighborsClassifier(n_neighbors=1, p=1,weights='uniform') \n",
    "best_KNN_model3.fit(X_train3, y_train3)\n",
    "\n",
    "# Predictions and accuracy scores\n",
    "y_pred_LDA3 = best_LDA_model3.predict(X_test3)\n",
    "y_pred_SVM3 = best_SVM_model3.predict(Xsc_test3)\n",
    "y_pred_KNN3 = best_KNN_model3.predict(X_test3)\n",
    "\n",
    "accuracy_LDA3 = accuracy_score(y_pred_LDA3, y_test3)\n",
    "accuracy_SVM3 = accuracy_score(y_pred_SVM3, y_test3)\n",
    "accuracy_KNN3 = accuracy_score(y_pred_KNN3, y_test3)\n",
    "\n",
    "print(\"Accuracy for LDA: \", accuracy_LDA3)\n",
    "print(\"Accuracy for SVM: \", accuracy_SVM3)\n",
    "print(\"Accuracy for KNN: \", accuracy_KNN3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion for Machine Learning Segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Everything went pretty well in this portion\n",
    " - The classifiers may have learned the wrong features based off of the data, so it might be predicting weirdly\n",
    " - Wrong features because data didn't support literature where alpha should be higher for eyes closed than eyes open\n",
    " - If the alpha powers in this data matched literature, then the classifier might have performed better and learned correct features, accuracy might have been higher\n",
    " - One extension I would have wanted to implement is leave-one-out cross validation\n",
    " - I implemented different splits of data to see if the classifiers would perform better based on the amount of training and testing data, and I also implemented a higher number of validation splits(usually 5 splits) for this purpose, as the dataset we ended up with was a little small.\n",
    " - Maybe leave-one-out cross validation would provide more unbiased results, but it could result in much higher variance in the validation scores, causing us to maybe go down a different path in terms of hyperparameters and models. \n",
    " - Also would have wanted to predict BDI instead of just binary classification\n",
    " - Data that matches most literature would also be another improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
